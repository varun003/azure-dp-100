{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3b521d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.37.0 to work with dp100-workspace\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9643b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: car-training\n",
      "Loading Data...\n",
      "training Logistic regression model\n",
      "Accuracy: 0.9180327868852459\n",
      "AUC: 0.6785714285714286\n",
      "Model trained and registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace = ws, name = \"car-training\")\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "car = pd.read_csv('data2/car-prediction2.csv')\n",
    "\n",
    "# applying label encoding\n",
    "pre = preprocessing.LabelEncoder()\n",
    "data = car.apply(pre.fit_transform)\n",
    "\n",
    "#Normalize the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "num_cols = ['Selling_Price','Present_Price','Kms_Driven','car_age']\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "\n",
    "# Separate features and labels\n",
    "x, y = data[['Selling_Price','Present_Price','Kms_Driven','Fuel_Type','Seller_Type','Transmission','car_age']].values, data['Owner'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=0)\n",
    "\n",
    "# training the model\n",
    "print('training Logistic regression model')\n",
    "\n",
    "reg= 0.02\n",
    "\n",
    "model=LogisticRegression(C=1/reg,solver=\"liblinear\").fit(x_train,y_train)\n",
    "# model = DecisionTreeClassifier().fit(x_train, y_train)\n",
    "# print('training Logistic regression model')\n",
    "# model=LogisticRegression(C=1/reg,solver=\"liblinear\").fit(x_train,y_train)\n",
    "\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(x_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(x_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'car_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/car_model.pkl', model_name='car_model',\n",
    "                   tags={'Training context':'Inline Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "print('Model trained and registered.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81657d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_model version: 18\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.6785714285714286\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "car_model version: 17\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.6785714285714286\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "car_model version: 16\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.6785714285714286\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "car_model version: 15\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.6785714285714286\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "car_model version: 14\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.5\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "car_model version: 13\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.5\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "diabetes_model version: 9\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8806209264142494\n",
      "\t Accuracy : 0.8946666666666667\n",
      "\n",
      "\n",
      "car_model version: 12\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.5\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "car_model version: 11\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.6928571428571428\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "car_model version: 10\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.6928571428571428\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "car_model version: 9\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.6642857142857143\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "car_model version: 8\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.5\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "diabetes_model version: 8\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8783521568237224\n",
      "\t Accuracy : 0.8913333333333333\n",
      "\n",
      "\n",
      "car_model version: 7\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.6892857142857143\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "car_model version: 6\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.5\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "car_model version: 5\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.6928571428571428\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "car_model version: 4\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.5\n",
      "\t Accuracy : 0.9180327868852459\n",
      "\n",
      "\n",
      "diabetes_model version: 7\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8766232150853275\n",
      "\t Accuracy : 0.8903333333333333\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "295f89b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_model version 18\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['car_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a94078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car-deploy2 folder created.\n"
     ]
    }
   ],
   "source": [
    "# Deploying Model as WebService\n",
    "\n",
    "import os\n",
    "\n",
    "folder_name = 'car-deploy2'\n",
    "\n",
    "# creating a folder for webservice\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(experiment_folder,exist_ok=True)\n",
    "print(folder_name, 'folder created.')\n",
    "\n",
    "# score script\n",
    "script_file = os.path.join(experiment_folder,\"score_car.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e8cbf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./car-deploy2/score_car.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = Model.get_model_path('car_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-sold', 'sold']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbec7214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in ./car-deploy2/car_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating enviroment\n",
    "\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv=CondaDependencies()\n",
    "myenv.add_conda_package('scikit-learn')\n",
    "\n",
    "env_file = os.path.join(experiment_folder,\"car_env.yml\")\n",
    "\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print('Saved dependency info in',env_file)\n",
    "\n",
    "# print yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94f7c5fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-01-21 09:04:57+00:00 Creating Container Registry if not exists.\n",
      "2022-01-21 09:04:57+00:00 Registering the environment.\n",
      "2022-01-21 09:05:00+00:00 Use the existing image.\n",
      "2022-01-21 09:05:01+00:00 Generating deployment configuration.\n",
      "2022-01-21 09:05:02+00:00 Submitting deployment to compute.\n",
      "2022-01-21 09:05:05+00:00 Checking the status of deployment car-service..\n",
      "2022-01-21 09:06:38+00:00 Checking the status of inference endpoint car-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "# Creating endpoint for deploying service\n",
    "\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   entry_script=script_file,\n",
    "                                   conda_file=env_file)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"car-service\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c48f937e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n",
      "2022-01-21T09:06:29,624132800+00:00 - iot-server/run \n",
      "2022-01-21T09:06:29,625637400+00:00 - rsyslog/run \n",
      "2022-01-21T09:06:29,627937200+00:00 - gunicorn/run \n",
      "Dynamic Python package installation is disabled.\n",
      "Starting HTTP server\n",
      "2022-01-21T09:06:29,685068100+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2022-01-21T09:06:29,997909200+00:00 - iot-server/finish 1 0\n",
      "2022-01-21T09:06:30,006605300+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (68)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 100\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2022-01-21 09:06:32,617 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2022-01-21 09:06:32,618 | root | INFO | Starting up request id generator\n",
      "2022-01-21 09:06:32,618 | root | INFO | Starting up app insight hooks\n",
      "2022-01-21 09:06:32,619 | root | INFO | Invoking user's init function\n",
      "no request id,/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.0 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "\n",
      "/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.0 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "2022-01-21 09:06:33,171 | root | INFO | Users's init has completed successfully\n",
      "  UserWarning)\n",
      "2022-01-21 09:06:33,179 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2022-01-21 09:06:33,180 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2022-01-21 09:06:33,182 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2022-01-21 09:13:50,056 | root | INFO | Swagger file not present\n",
      "2022-01-21 09:13:50,057 | root | INFO | 404\n",
      "127.0.0.1 - - [21/Jan/2022:09:13:50 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2022-01-21 09:13:51,867 | root | INFO | Swagger file not present\n",
      "2022-01-21 09:13:51,868 | root | INFO | 404\n",
      "127.0.0.1 - - [21/Jan/2022:09:13:51 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking health of service\n",
    "\n",
    "print(service.state)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf95481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car: [0.38, 0.38, 0.42, 2, 0, 1, 0.27]\n",
      "not-sold\n"
     ]
    }
   ],
   "source": [
    "# Using the webservice\n",
    "\n",
    "import json\n",
    "\n",
    "# x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
    "x_new = [[0.38,0.38,0.42,2,0,1,0.27]]\n",
    "print ('car: {}'.format(x_new[0]))\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "predicted_classes = json.loads(predictions)\n",
    "print(predicted_classes[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
